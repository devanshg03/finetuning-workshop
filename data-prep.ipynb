{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation for WhatsApp Chat Finetuning\n",
    "\n",
    "This notebook processes a WhatsApp chat export file to prepare it for finetuning a language model. The main steps include:\n",
    "\n",
    "1. Reading the WhatsApp chat export file\n",
    "2. Extracting and concatenating messages from specific users\n",
    "3. Formatting the data into a structure suitable for model training\n",
    "4. Saving the processed data in a format ready for finetuning\n",
    "\n",
    "The goal is to create a dataset that represents conversations between two specific users, which will be used to train a model to mimic one of the user's communication style.\n",
    "\n",
    "#### To use this notebook:\n",
    "1. Replace 'Your Name' with your actual name as it appears in the WhatsApp chat\n",
    "2. Replace 'Friend' with the name of the person you're chatting with\n",
    "3. Ensure your WhatsApp chat export file is named 'messages.txt' and placed in the 'data/whatsapp/' directory\n",
    "4. Run all cells in this notebook to process the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Necessary Libraries\n",
    "import json, re\n",
    "\n",
    "# Variables\n",
    "name = \"Your Name\"\n",
    "friend_name = \"Friend\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing the logic to read the text file and concatenate consecutive messages, and then convert them to JSONL\n",
    "\n",
    "with open('data/whatsapp/messages.txt', 'r') as file:\n",
    "    text = file.read()\n",
    "\n",
    "# Extract the data from the text file\n",
    "lines = text.split('\\n')\n",
    "\n",
    "# Initialize variables to hold concatenated messages and the previous speaker\n",
    "user_messages = []\n",
    "assistant_messages = []\n",
    "previous_speaker = None\n",
    "\n",
    "# Process each line\n",
    "for line in lines:\n",
    "    # Extract the timestamp, speaker, and message using regex\n",
    "    match = re.match(r'\\[.*?\\] (.*?): (.*)', line)\n",
    "    if match:\n",
    "        speaker = match.group(1).strip()\n",
    "        message = match.group(2).strip()\n",
    "\n",
    "        if speaker.startswith(name):\n",
    "            if previous_speaker == name:\n",
    "                # Continue the user's message\n",
    "                user_messages[-1] += \"\\n\" + message\n",
    "            else:\n",
    "                # New user's message\n",
    "                user_messages.append(message)\n",
    "                previous_speaker = name\n",
    "        elif speaker.startswith(friend_name):\n",
    "            if previous_speaker == friend_name:\n",
    "                # Continue the assistant's message\n",
    "                assistant_messages[-1] += \"\\n\" + message\n",
    "            else:\n",
    "                # New assistant's message\n",
    "                assistant_messages.append(message)\n",
    "                previous_speaker = friend_name\n",
    "\n",
    "# Combine user and assistant messages into JSONL format\n",
    "jsonl_output = []\n",
    "for user_msg, assistant_msg in zip(user_messages, assistant_messages):\n",
    "    entry = {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"content\": user_msg},\n",
    "            {\"role\": \"assistant\", \"content\": assistant_msg}\n",
    "        ]\n",
    "    }\n",
    "    jsonl_output.append(json.dumps(entry))\n",
    "\n",
    "# Show the final JSONL output\n",
    "with open('data/whatsapp/output.jsonl', 'w') as jsonl_file:\n",
    "    for entry in jsonl_output:\n",
    "        jsonl_file.write(entry + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the existing JSONL data\n",
    "with open('data/whatsapp/output.jsonl', 'r') as part1_file:\n",
    "    lines = part1_file.readlines()\n",
    "\n",
    "# Calculate the split indices for train, valid, and test\n",
    "train_split_index = int(len(lines) * 0.6)  # 60% for training\n",
    "valid_split_index = int(len(lines) * 0.8)  # 20% for validation, 20% for testing\n",
    "\n",
    "# Write the training data to a new file\n",
    "with open('data/whatsapp/train.jsonl', 'w') as train_file:\n",
    "    for line in lines[:train_split_index]:\n",
    "        # Add the system message to each line\n",
    "        user_assistant_message = json.loads(line)\n",
    "        user_assistant_message['messages'].insert(0, {\"role\": \"system\", \"content\": f\"You are {name}, a student at the University of Hong Kong.\"})\n",
    "        train_file.write(json.dumps(user_assistant_message) + '\\n')\n",
    "\n",
    "# Write the validation data to a new file\n",
    "with open('data/whatsapp/valid.jsonl', 'w') as valid_file:\n",
    "    for line in lines[train_split_index:valid_split_index]:\n",
    "        # Add the system message to each line\n",
    "        user_assistant_message = json.loads(line)\n",
    "        user_assistant_message['messages'].insert(0, {\"role\": \"system\", \"content\": f\"You are {name}, a student at the University of Hong Kong.\"})\n",
    "        valid_file.write(json.dumps(user_assistant_message) + '\\n')\n",
    "\n",
    "# Write the testing data to a new file\n",
    "with open('data/whatsapp/test.jsonl', 'w') as test_file:\n",
    "    for line in lines[valid_split_index:]:\n",
    "        # Add the system message to each line\n",
    "        user_assistant_message = json.loads(line)\n",
    "        user_assistant_message['messages'].insert(0, {\"role\": \"system\", \"content\": f\"You are {name}, a student at the University of Hong Kong.\"})\n",
    "        test_file.write(json.dumps(user_assistant_message) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate Data Splits and Integrity\n",
    "\n",
    "This section checks if we have successfully created train, valid, and test splits, and ensures all the data is valid.\n",
    "\n",
    "We will:\n",
    "1. Verify the existence of train, valid, and test files\n",
    "2. Check if each file contains valid JSONL entries\n",
    "3. Confirm that each entry has the correct structure (messages list with system, user, and assistant roles)\n",
    "4. Report the number of valid entries in each file\n",
    "\n",
    "The code below performs these checks and provides a summary of the validation results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test data validity\n",
    "import json\n",
    "import os\n",
    "\n",
    "def validate_jsonl_file(file_path):\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"Error: The file {file_path} does not exist.\")\n",
    "        return 0\n",
    "    else:\n",
    "        with open(file_path, 'r') as file:\n",
    "            valid_entries = []\n",
    "            for line_number, line in enumerate(file, start=1):\n",
    "                try:\n",
    "                    entry = json.loads(line)\n",
    "                    # Check if the entry has the required structure\n",
    "                    if 'messages' in entry and isinstance(entry['messages'], list):\n",
    "                        valid_entries.append(entry)\n",
    "                    else:\n",
    "                        print(f\"Invalid entry found at line {line_number}: {line.strip()}\")\n",
    "                except json.JSONDecodeError:\n",
    "                    print(f\"Error decoding JSON for line {line_number}: {line.strip()}\")\n",
    "        print(f\"Validation complete. {len(valid_entries)} valid entries found in {file_path}.\")\n",
    "        return len(valid_entries)\n",
    "\n",
    "# Validate the train, valid, and test files\n",
    "file_paths = ['data/whatsapp/train.jsonl', 'data/whatsapp/valid.jsonl', 'data/whatsapp/test.jsonl']\n",
    "for file_path in file_paths:\n",
    "    validate_jsonl_file(file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
